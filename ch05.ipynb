{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 50;\n                var nbb_unformatted_code = \"%load_ext nb_black\\nimport numpy as np \\nimport matplotlib.pyplot as plt\\nimport pickle\";\n                var nbb_formatted_code = \"%load_ext nb_black\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport pickle\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 51;\n                var nbb_unformatted_code = \"def sigmoid(x):\\n    return 1 / (1 + np.exp(-x))\\n\\n\\ndef softmax(x):\\n    x = x - np.max(x, axis=-1, keepdims=True)   # overflow\\n    return np.exp(x) / np.sum(np.exp(x), axis=-1, keepdims=True)\";\n                var nbb_formatted_code = \"def sigmoid(x):\\n    return 1 / (1 + np.exp(-x))\\n\\n\\ndef softmax(x):\\n    x = x - np.max(x, axis=-1, keepdims=True)  # overflow\\n    return np.exp(x) / np.sum(np.exp(x), axis=-1, keepdims=True)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    x = x - np.max(x, axis=-1, keepdims=True)   # overflow\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 52;\n                var nbb_unformatted_code = \"class MulLayer:\\n    def __init__(self):\\n        self.x = None\\n        self.y = None \\n\\n    def forward(self, x, y):\\n        self.x = x \\n        self.y = y \\n        return x * y \\n\\n    def backward(self, dout):\\n        dx = dout * self.y \\n        dy = dout * self.x \\n        return dx, dy\";\n                var nbb_formatted_code = \"class MulLayer:\\n    def __init__(self):\\n        self.x = None\\n        self.y = None\\n\\n    def forward(self, x, y):\\n        self.x = x\\n        self.y = y\\n        return x * y\\n\\n    def backward(self, dout):\\n        dx = dout * self.y\\n        dy = dout * self.x\\n        return dx, dy\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None \n",
    "\n",
    "    def forward(self, x, y):\n",
    "        self.x = x \n",
    "        self.y = y \n",
    "        return x * y \n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y \n",
    "        dy = dout * self.x \n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n",
      "2.2 110.00000000000001 200\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 53;\n                var nbb_unformatted_code = \"apple = 100 \\nnapple = 2 \\ntax = 1.1 \\n\\nmul_apple_layer = MulLayer()\\nmul_tax_layer = MulLayer()\\napple_price = mul_apple_layer.forward(apple, napple)\\nprice = mul_tax_layer.forward(apple_price, tax)\\nprint(price)\\n\\ndprice = 1\\ndapple_price, dtax = mul_tax_layer.backward(dprice)\\ndapple, dnapple = mul_apple_layer.backward(dapple_price)\\nprint(dapple, dnapple, dtax)\";\n                var nbb_formatted_code = \"apple = 100\\nnapple = 2\\ntax = 1.1\\n\\nmul_apple_layer = MulLayer()\\nmul_tax_layer = MulLayer()\\napple_price = mul_apple_layer.forward(apple, napple)\\nprice = mul_tax_layer.forward(apple_price, tax)\\nprint(price)\\n\\ndprice = 1\\ndapple_price, dtax = mul_tax_layer.backward(dprice)\\ndapple, dnapple = mul_apple_layer.backward(dapple_price)\\nprint(dapple, dnapple, dtax)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apple = 100 \n",
    "napple = 2 \n",
    "tax = 1.1 \n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "apple_price = mul_apple_layer.forward(apple, napple)\n",
    "price = mul_tax_layer.forward(apple_price, tax)\n",
    "print(price)\n",
    "\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dnapple = mul_apple_layer.backward(dapple_price)\n",
    "print(dapple, dnapple, dtax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 54;\n                var nbb_unformatted_code = \"class AddLayer:\\n    def __init__(self):\\n        pass \\n\\n    def forward(self, x, y):\\n        return x + y \\n\\n    def backward(self, dout):\\n        return dout, dout \";\n                var nbb_formatted_code = \"class AddLayer:\\n    def __init__(self):\\n        pass\\n\\n    def forward(self, x, y):\\n        return x + y\\n\\n    def backward(self, dout):\\n        return dout, dout\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass \n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return x + y \n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout, dout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715.0000000000001\n",
      "110.00000000000001 2.2 3.3000000000000003 165.0 650\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 55;\n                var nbb_unformatted_code = \"apple = 100 \\napple_num = 2 \\norange = 150 \\norange_num = 3 \\ntax = 1.1\\n# layer\\nmul_apple_layer = MulLayer() \\nmul_orange_layer = MulLayer() \\nadd_apple_orange_layer = AddLayer() \\nmul_tax_layer = MulLayer()\\n# forward\\napple_price = mul_apple_layer.forward(apple, apple_num) #(1)\\norange_price = mul_orange_layer.forward(orange, orange_num) #(2)\\nall_price = add_apple_orange_layer.forward(apple_price, orange_price) #(3) \\nprice = mul_tax_layer.forward(all_price, tax) #(4)\\n# backward\\ndprice = 1\\ndall_price, dtax = mul_tax_layer.backward(dprice) #(4)\\ndapple_price, dorange_price = add_apple_orange_layer.backward(dall_price) #(3) \\ndorange, dorange_num = mul_orange_layer.backward(dorange_price) #(2)\\ndapple, dapple_num = mul_apple_layer.backward(dapple_price) #(1)\\nprint(price) # 715\\nprint(dapple_num, dapple, dorange, dorange_num, dtax) # 110 2.2 3.3 165 650\";\n                var nbb_formatted_code = \"apple = 100\\napple_num = 2\\norange = 150\\norange_num = 3\\ntax = 1.1\\n# layer\\nmul_apple_layer = MulLayer()\\nmul_orange_layer = MulLayer()\\nadd_apple_orange_layer = AddLayer()\\nmul_tax_layer = MulLayer()\\n# forward\\napple_price = mul_apple_layer.forward(apple, apple_num)  # (1)\\norange_price = mul_orange_layer.forward(orange, orange_num)  # (2)\\nall_price = add_apple_orange_layer.forward(apple_price, orange_price)  # (3)\\nprice = mul_tax_layer.forward(all_price, tax)  # (4)\\n# backward\\ndprice = 1\\ndall_price, dtax = mul_tax_layer.backward(dprice)  # (4)\\ndapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)  # (3)\\ndorange, dorange_num = mul_orange_layer.backward(dorange_price)  # (2)\\ndapple, dapple_num = mul_apple_layer.backward(dapple_price)  # (1)\\nprint(price)  # 715\\nprint(dapple_num, dapple, dorange, dorange_num, dtax)  # 110 2.2 3.3 165 650\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apple = 100 \n",
    "apple_num = 2 \n",
    "orange = 150 \n",
    "orange_num = 3 \n",
    "tax = 1.1\n",
    "# layer\n",
    "mul_apple_layer = MulLayer() \n",
    "mul_orange_layer = MulLayer() \n",
    "add_apple_orange_layer = AddLayer() \n",
    "mul_tax_layer = MulLayer()\n",
    "# forward\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num) #(1)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num) #(2)\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price) #(3) \n",
    "price = mul_tax_layer.forward(all_price, tax) #(4)\n",
    "# backward\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice) #(4)\n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price) #(3) \n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price) #(2)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price) #(1)\n",
    "print(price) # 715\n",
    "print(dapple_num, dapple, dorange, dorange_num, dtax) # 110 2.2 3.3 165 650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 56;\n                var nbb_unformatted_code = \"class Relu:\\n    def __init__(self):\\n        self.mask = None \\n\\n    def forward(self, x):\\n        self.mask = (x <= 0)\\n        out = x.copy()\\n        out[self.mask] = 0 \\n        return out \\n\\n    def backward(self, dout):\\n        dout[self.mask] = 0\\n        dx = dout \\n        return dx\";\n                var nbb_formatted_code = \"class Relu:\\n    def __init__(self):\\n        self.mask = None\\n\\n    def forward(self, x):\\n        self.mask = x <= 0\\n        out = x.copy()\\n        out[self.mask] = 0\\n        return out\\n\\n    def backward(self, dout):\\n        dout[self.mask] = 0\\n        dx = dout\\n        return dx\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None \n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0 \n",
    "        return out \n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 64;\n                var nbb_unformatted_code = \"class Sigmoid:\\n    def __init__(self):\\n        self.out = None\\n\\n    def forward(self, x):\\n        self.out = sigmoid(x) \\n        return self.out\\n\\n    def backward(self, dout):\\n        dx = dout * (1.0 - self.out) * self.out\\n        return dx\";\n                var nbb_formatted_code = \"class Sigmoid:\\n    def __init__(self):\\n        self.out = None\\n\\n    def forward(self, x):\\n        self.out = sigmoid(x)\\n        return self.out\\n\\n    def backward(self, dout):\\n        dx = dout * (1.0 - self.out) * self.out\\n        return dx\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.out = sigmoid(x) \n",
    "        return self.out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 58;\n                var nbb_unformatted_code = \"class Affine:\\n    def __init__(self, w, b):\\n        self.w = w\\n        self.b = b \\n\\n        self.x = None \\n        self.original_x_shape = None \\n        self.dw = None \\n        self.db = None \\n\\n    def forward(self, x):\\n        self.original_x_shape = x.shape \\n        x = x.reshape(x.shape[0], -1)\\n        self.x = x \\n\\n        return np.dot(self.x, self.w) + self.b \\n\\n    def backward(self, dout):\\n        dx = np.dot(dout, self.w.T)\\n        self.dw = np.dot(self.x.T, dout)\\n        self.db = np.sum(dout, axis=0)\\n        dx = dx.reshape(*self.original_x_shape)\\n        return dx \";\n                var nbb_formatted_code = \"class Affine:\\n    def __init__(self, w, b):\\n        self.w = w\\n        self.b = b\\n\\n        self.x = None\\n        self.original_x_shape = None\\n        self.dw = None\\n        self.db = None\\n\\n    def forward(self, x):\\n        self.original_x_shape = x.shape\\n        x = x.reshape(x.shape[0], -1)\\n        self.x = x\\n\\n        return np.dot(self.x, self.w) + self.b\\n\\n    def backward(self, dout):\\n        dx = np.dot(dout, self.w.T)\\n        self.dw = np.dot(self.x.T, dout)\\n        self.db = np.sum(dout, axis=0)\\n        dx = dx.reshape(*self.original_x_shape)\\n        return dx\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Affine:\n",
    "    def __init__(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b \n",
    "\n",
    "        self.x = None \n",
    "        self.original_x_shape = None \n",
    "        self.dw = None \n",
    "        self.db = None \n",
    "\n",
    "    def forward(self, x):\n",
    "        self.original_x_shape = x.shape \n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x \n",
    "\n",
    "        return np.dot(self.x, self.w) + self.b \n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.w.T)\n",
    "        self.dw = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        dx = dx.reshape(*self.original_x_shape)\n",
    "        return dx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 65;\n                var nbb_unformatted_code = \"def cross_entropy_error(y, t):\\n    if y.ndim == 1:\\n        t = t.reshape(1, t.size)\\n        y = y.reshape(1, y.size)\\n\\n    if t.size == y.size: # one-hot-vector\\n        t = t.argmax(axis=1)\\n    batch_size = y.shape[0]\\n    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\\n\\n\\nclass SoftmaxWithLoss:\\n    def __init__(self):\\n        self.loss = None \\n        self.y = None \\n        self.t = None \\n\\n    def forward(self, x, t):\\n        self.t = t \\n        self.y = softmax(x)\\n        self.loss = cross_entropy_error(self.y, self.t)\\n        return self.loss \\n\\n    def backward(self, dout=1):\\n        batch_size = self.t.shape[0]\\n        if self.t.size == self.y.size: # one-hot-vector\\n            dx = (self.y - self.t) / batch_size\\n        else:\\n            dx = self.y.copy()\\n            dx[np.arange(batch_size), self.t] -= 1 \\n            dx = dx/ batch_size\\n        return dx \";\n                var nbb_formatted_code = \"def cross_entropy_error(y, t):\\n    if y.ndim == 1:\\n        t = t.reshape(1, t.size)\\n        y = y.reshape(1, y.size)\\n\\n    if t.size == y.size:  # one-hot-vector\\n        t = t.argmax(axis=1)\\n    batch_size = y.shape[0]\\n    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\\n\\n\\nclass SoftmaxWithLoss:\\n    def __init__(self):\\n        self.loss = None\\n        self.y = None\\n        self.t = None\\n\\n    def forward(self, x, t):\\n        self.t = t\\n        self.y = softmax(x)\\n        self.loss = cross_entropy_error(self.y, self.t)\\n        return self.loss\\n\\n    def backward(self, dout=1):\\n        batch_size = self.t.shape[0]\\n        if self.t.size == self.y.size:  # one-hot-vector\\n            dx = (self.y - self.t) / batch_size\\n        else:\\n            dx = self.y.copy()\\n            dx[np.arange(batch_size), self.t] -= 1\\n            dx = dx / batch_size\\n        return dx\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "\n",
    "    if t.size == y.size: # one-hot-vector\n",
    "        t = t.argmax(axis=1)\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None \n",
    "        self.y = None \n",
    "        self.t = None \n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t \n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss \n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        if self.t.size == self.y.size: # one-hot-vector\n",
    "            dx = (self.y - self.t) / batch_size\n",
    "        else:\n",
    "            dx = self.y.copy()\n",
    "            dx[np.arange(batch_size), self.t] -= 1 \n",
    "            dx = dx/ batch_size\n",
    "        return dx \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 67;\n                var nbb_unformatted_code = \"def numerical_gradient(f, x):\\n    h = 1e-4\\n    grad = np.zeros_like(x)\\n\\n    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\\n    while not it.finished:\\n        idx = it.multi_index\\n        tmp_val = x[idx]\\n        x[idx] = tmp_val + h\\n        fxh1 = f(x)  # f(x + h)\\n        \\n        x[idx] = tmp_val - h\\n        fxh2 = f(x)  # f(x - h)\\n        grad[idx] = (fxh1 - fxh2) / (2 * h)\\n\\n        x[idx] = tmp_val\\n        it.iternext()\\n    \\n    return grad\";\n                var nbb_formatted_code = \"def numerical_gradient(f, x):\\n    h = 1e-4\\n    grad = np.zeros_like(x)\\n\\n    it = np.nditer(x, flags=[\\\"multi_index\\\"], op_flags=[\\\"readwrite\\\"])\\n    while not it.finished:\\n        idx = it.multi_index\\n        tmp_val = x[idx]\\n        x[idx] = tmp_val + h\\n        fxh1 = f(x)  # f(x + h)\\n\\n        x[idx] = tmp_val - h\\n        fxh2 = f(x)  # f(x - h)\\n        grad[idx] = (fxh1 - fxh2) / (2 * h)\\n\\n        x[idx] = tmp_val\\n        it.iternext()\\n\\n    return grad\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)  # f(x + h)\n",
    "        \n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)  # f(x - h)\n",
    "        grad[idx] = (fxh1 - fxh2) / (2 * h)\n",
    "\n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 68;\n                var nbb_unformatted_code = \"from collections import OrderedDict\\n\\n\\nclass TwoLayerNet:\\n    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\\n        self.params = {}\\n        self.params[\\\"w1\\\"] = weight_init_std * np.random.randn(input_size, hidden_size)\\n        self.params[\\\"b1\\\"] = np.zeros(hidden_size)\\n        self.params[\\\"w2\\\"] = weight_init_std * np.random.randn(hidden_size, output_size)\\n        self.params[\\\"b2\\\"] = np.zeros(output_size)\\n\\n        self.layers = OrderedDict()\\n        self.layers[\\\"Affine1\\\"] = Affine(self.params[\\\"w1\\\"], self.params[\\\"b1\\\"])\\n        self.layers[\\\"Relu1\\\"] = Relu()\\n        self.layers[\\\"Affine2\\\"] = Affine(self.params[\\\"w2\\\"], self.params[\\\"b2\\\"])\\n\\n        self.last_layer = SoftmaxWithLoss()\\n\\n    def predict(self, x):\\n        for layer in self.layers.values():\\n            x = layer.forward(x)\\n        return x\\n\\n    def loss(self, x, t):\\n        y = self.predict(x)\\n        return self.last_layer.forward(y, t)\\n\\n    def accuracy(self, x, t):\\n        y = self.predict(x)\\n        y = np.argmax(y, axis=1)\\n        if t.ndim != 1:\\n            t = np.argmax(t, axis=1)\\n        accuracy = np.sum(y == t) / float(x.shape[0])\\n        return accuracy\\n\\n    def numerical_gradient(self, x, t):\\n        loss_w = lambda w: self.loss(x, t)\\n\\n        grads = {}\\n        grads[\\\"w1\\\"] = numerical_gradient(loss_w, self.params[\\\"w1\\\"])\\n        grads[\\\"b1\\\"] = numerical_gradient(loss_w, self.params[\\\"b1\\\"])\\n        grads[\\\"w2\\\"] = numerical_gradient(loss_w, self.params[\\\"w2\\\"])\\n        grads[\\\"b2\\\"] = numerical_gradient(loss_w, self.params[\\\"b2\\\"])\\n\\n        return grads\\n\\n    def gradient(self, x, t):\\n        # forward\\n        self.loss(x, t)\\n\\n        # backward\\n        dout = 1.0\\n        dout = self.last_layer.backward(dout)\\n        layers = list(self.layers.values())\\n        layers.reverse()\\n        for layer in layers:\\n            dout = layer.backward(dout)\\n\\n        grads = {}\\n        grads[\\\"w1\\\"] = self.layers[\\\"Affine1\\\"].dw\\n        grads[\\\"b1\\\"] = self.layers[\\\"Affine1\\\"].db\\n        grads[\\\"w2\\\"] = self.layers[\\\"Affine2\\\"].dw\\n        grads[\\\"b2\\\"] = self.layers[\\\"Affine2\\\"].db\\n        return grads\";\n                var nbb_formatted_code = \"from collections import OrderedDict\\n\\n\\nclass TwoLayerNet:\\n    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\\n        self.params = {}\\n        self.params[\\\"w1\\\"] = weight_init_std * np.random.randn(input_size, hidden_size)\\n        self.params[\\\"b1\\\"] = np.zeros(hidden_size)\\n        self.params[\\\"w2\\\"] = weight_init_std * np.random.randn(hidden_size, output_size)\\n        self.params[\\\"b2\\\"] = np.zeros(output_size)\\n\\n        self.layers = OrderedDict()\\n        self.layers[\\\"Affine1\\\"] = Affine(self.params[\\\"w1\\\"], self.params[\\\"b1\\\"])\\n        self.layers[\\\"Relu1\\\"] = Relu()\\n        self.layers[\\\"Affine2\\\"] = Affine(self.params[\\\"w2\\\"], self.params[\\\"b2\\\"])\\n\\n        self.last_layer = SoftmaxWithLoss()\\n\\n    def predict(self, x):\\n        for layer in self.layers.values():\\n            x = layer.forward(x)\\n        return x\\n\\n    def loss(self, x, t):\\n        y = self.predict(x)\\n        return self.last_layer.forward(y, t)\\n\\n    def accuracy(self, x, t):\\n        y = self.predict(x)\\n        y = np.argmax(y, axis=1)\\n        if t.ndim != 1:\\n            t = np.argmax(t, axis=1)\\n        accuracy = np.sum(y == t) / float(x.shape[0])\\n        return accuracy\\n\\n    def numerical_gradient(self, x, t):\\n        loss_w = lambda w: self.loss(x, t)\\n\\n        grads = {}\\n        grads[\\\"w1\\\"] = numerical_gradient(loss_w, self.params[\\\"w1\\\"])\\n        grads[\\\"b1\\\"] = numerical_gradient(loss_w, self.params[\\\"b1\\\"])\\n        grads[\\\"w2\\\"] = numerical_gradient(loss_w, self.params[\\\"w2\\\"])\\n        grads[\\\"b2\\\"] = numerical_gradient(loss_w, self.params[\\\"b2\\\"])\\n\\n        return grads\\n\\n    def gradient(self, x, t):\\n        # forward\\n        self.loss(x, t)\\n\\n        # backward\\n        dout = 1.0\\n        dout = self.last_layer.backward(dout)\\n        layers = list(self.layers.values())\\n        layers.reverse()\\n        for layer in layers:\\n            dout = layer.backward(dout)\\n\\n        grads = {}\\n        grads[\\\"w1\\\"] = self.layers[\\\"Affine1\\\"].dw\\n        grads[\\\"b1\\\"] = self.layers[\\\"Affine1\\\"].db\\n        grads[\\\"w2\\\"] = self.layers[\\\"Affine2\\\"].dw\\n        grads[\\\"b2\\\"] = self.layers[\\\"Affine2\\\"].db\\n        return grads\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        self.params = {}\n",
    "        self.params[\"w1\"] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params[\"b1\"] = np.zeros(hidden_size)\n",
    "        self.params[\"w2\"] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params[\"b2\"] = np.zeros(output_size)\n",
    "\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers[\"Affine1\"] = Affine(self.params[\"w1\"], self.params[\"b1\"])\n",
    "        self.layers[\"Relu1\"] = Relu()\n",
    "        self.layers[\"Affine2\"] = Affine(self.params[\"w2\"], self.params[\"b2\"])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1:\n",
    "            t = np.argmax(t, axis=1)\n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        grads[\"w1\"] = numerical_gradient(loss_w, self.params[\"w1\"])\n",
    "        grads[\"b1\"] = numerical_gradient(loss_w, self.params[\"b1\"])\n",
    "        grads[\"w2\"] = numerical_gradient(loss_w, self.params[\"w2\"])\n",
    "        grads[\"b2\"] = numerical_gradient(loss_w, self.params[\"b2\"])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1.0\n",
    "        dout = self.last_layer.backward(dout)\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        grads = {}\n",
    "        grads[\"w1\"] = self.layers[\"Affine1\"].dw\n",
    "        grads[\"b1\"] = self.layers[\"Affine1\"].db\n",
    "        grads[\"w2\"] = self.layers[\"Affine2\"].dw\n",
    "        grads[\"b2\"] = self.layers[\"Affine2\"].db\n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: 3.9584387223858237e-10\n",
      "b1: 2.2756062378914177e-09\n",
      "w2: 5.158656588409856e-09\n",
      "b2: 1.3935433495204652e-07\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 69;\n                var nbb_unformatted_code = \"from mnist import load_mnist\\n\\n(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\\n\\nnetwork = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\\n\\nx_batch = x_train[:3]\\nt_batch = t_train[:3]\\n\\ngrad_numerical = network.numerical_gradient(x_batch, t_batch)\\ngrad_backprop = network.gradient(x_batch, t_batch)\\n\\nfor key in grad_numerical.keys():\\n    diff = np.average(np.abs(grad_backprop[key] - grad_numerical[key]))\\n    print(f\\\"{key}: {diff}\\\")\";\n                var nbb_formatted_code = \"from mnist import load_mnist\\n\\n(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\\n\\nnetwork = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\\n\\nx_batch = x_train[:3]\\nt_batch = t_train[:3]\\n\\ngrad_numerical = network.numerical_gradient(x_batch, t_batch)\\ngrad_backprop = network.gradient(x_batch, t_batch)\\n\\nfor key in grad_numerical.keys():\\n    diff = np.average(np.abs(grad_backprop[key] - grad_numerical[key]))\\n    print(f\\\"{key}: {diff}\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average(np.abs(grad_backprop[key] - grad_numerical[key]))\n",
    "    print(f\"{key}: {diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09928333333333333 0.1\n",
      "0.9001833333333333 0.904\n",
      "0.9246 0.9269\n",
      "0.9375666666666667 0.9373\n",
      "0.9424333333333333 0.9419\n",
      "0.9520833333333333 0.9497\n",
      "0.9568833333333333 0.9526\n",
      "0.9606166666666667 0.956\n",
      "0.9621666666666666 0.9584\n",
      "0.9654166666666667 0.9608\n",
      "0.9679333333333333 0.9627\n",
      "0.9709166666666667 0.9657\n",
      "0.9712 0.9656\n",
      "0.9742333333333333 0.9685\n",
      "0.9755666666666667 0.9682\n",
      "0.9778166666666667 0.9694\n",
      "0.9795333333333334 0.971\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 70;\n                var nbb_unformatted_code = \"from mnist import load_mnist\\n\\n(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\\n\\nnetwork = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\\n\\nniter = 10000\\ntrain_size = x_train.shape[0]\\nbatch_size = 100\\nlearning_rate = 0.1 \\n\\ntrain_loss_list, train_acc_list, test_acc_list = [], [], []\\niter_per_epoch = max(train_size / batch_size, 1)\\n\\nfor i in range(niter):\\n    batch_mask = np.random.choice(train_size, batch_size)\\n    x_batch = x_train[batch_mask]\\n    t_batch = t_train[batch_mask]\\n\\n    grad = network.gradient(x_batch, t_batch)\\n\\n    for key in ('w1', 'b1', 'w2', 'b2'):\\n        network.params[key] -= learning_rate * grad[key]\\n\\n    loss = network.loss(x_batch, t_batch)\\n    train_loss_list.append(loss)\\n\\n    if i % iter_per_epoch == 0:\\n        train_acc = network.accuracy(x_train, t_train)\\n        test_acc = network.accuracy(x_test, t_test)\\n        train_acc_list.append(train_acc)\\n        test_acc_list.append(test_acc)\\n        print(train_acc, test_acc)\";\n                var nbb_formatted_code = \"from mnist import load_mnist\\n\\n(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\\n\\nnetwork = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\\n\\nniter = 10000\\ntrain_size = x_train.shape[0]\\nbatch_size = 100\\nlearning_rate = 0.1\\n\\ntrain_loss_list, train_acc_list, test_acc_list = [], [], []\\niter_per_epoch = max(train_size / batch_size, 1)\\n\\nfor i in range(niter):\\n    batch_mask = np.random.choice(train_size, batch_size)\\n    x_batch = x_train[batch_mask]\\n    t_batch = t_train[batch_mask]\\n\\n    grad = network.gradient(x_batch, t_batch)\\n\\n    for key in (\\\"w1\\\", \\\"b1\\\", \\\"w2\\\", \\\"b2\\\"):\\n        network.params[key] -= learning_rate * grad[key]\\n\\n    loss = network.loss(x_batch, t_batch)\\n    train_loss_list.append(loss)\\n\\n    if i % iter_per_epoch == 0:\\n        train_acc = network.accuracy(x_train, t_train)\\n        test_acc = network.accuracy(x_test, t_test)\\n        train_acc_list.append(train_acc)\\n        test_acc_list.append(test_acc)\\n        print(train_acc, test_acc)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "niter = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1 \n",
    "\n",
    "train_loss_list, train_acc_list, test_acc_list = [], [], []\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(niter):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "\n",
    "    for key in ('w1', 'b1', 'w2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86ca7daf8d2d0ca61d31c7f32d928d7e2c460b26f8cfe91a23c8c2e79a8ef6c9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
